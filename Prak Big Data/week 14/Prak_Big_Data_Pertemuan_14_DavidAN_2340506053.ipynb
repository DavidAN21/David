{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9ae225b",
      "metadata": {
        "id": "d9ae225b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5880e8c9-b156-4d3f-a4fa-4c91204d4521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [0.9999999999999992]\n",
            "Intercept: 15.000000000000009\n"
          ]
        }
      ],
      "source": [
        "# Example: Linear Regression with Spark MLlib\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName('MLlib Example').getOrCreate()\n",
        "\n",
        "# Load sample data\n",
        "data = [(1, 5.0, 20.0), (2, 10.0, 25.0), (3, 15.0, 30.0), (4, 20.0, 35.0)]\n",
        "columns = ['ID', 'Feature', 'Target']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Prepare data for modeling\n",
        "assembler = VectorAssembler(inputCols=['Feature'], outputCol='Features')\n",
        "df_transformed = assembler.transform(df)\n",
        "\n",
        "# Train a linear regression model\n",
        "lr = LinearRegression(featuresCol='Features', labelCol='Target')\n",
        "model = lr.fit(df_transformed)\n",
        "\n",
        "# Print model coefficients\n",
        "print(f'Coefficients: {model.coefficients}')\n",
        "print(f'Intercept: {model.intercept}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.linalg import Vectors, VectorUDT\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType\n",
        "from pyspark.ml.linalg import DenseVector\n",
        "\n",
        "# Start a SparkSession\n",
        "spark = SparkSession.builder.appName(\"LogisticRegressionExample\").getOrCreate()\n",
        "\n",
        "# Example dataset\n",
        "data = [\n",
        "    (1, (2.0, 3.0), 0),\n",
        "    (2, (1.0, 5.0), 1),\n",
        "    (3, (2.5, 4.5), 1),\n",
        "    (4, (3.0, 6.0), 0)\n",
        "]\n",
        "columns = ['ID', 'Features', 'Label']\n",
        "\n",
        "# Create initial DataFrame\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "\n",
        "# UDF to convert array to DenseVector\n",
        "def array_to_vector(array):\n",
        "    return DenseVector(array)\n",
        "\n",
        "# Explicitly specify the return type as VectorUDT\n",
        "vector_udf = udf(array_to_vector, VectorUDT())\n",
        "\n",
        "# Apply UDF to create a new column with DenseVector\n",
        "df = df.withColumn(\"features\", vector_udf(df[\"Features\"]))\n",
        "\n",
        "# Check schema to confirm transformation\n",
        "df.printSchema()\n",
        "\n",
        "# Train logistic regression model\n",
        "lr = LogisticRegression(featuresCol='features', labelCol='Label')\n",
        "model = lr.fit(df)\n",
        "\n",
        "# Display coefficients and intercept\n",
        "print(f\"Coefficients: {model.coefficients}\")\n",
        "print(f\"Intercept: {model.intercept}\")\n",
        "\n",
        "# Test model predictions\n",
        "predictions = model.transform(df)\n",
        "predictions.select(\"ID\", \"features\", \"Label\", \"prediction\", \"probability\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn4zfNgqn7vY",
        "outputId": "ad9e460d-5821-47dd-c7f2-29d4aa988a27"
      },
      "id": "Zn4zfNgqn7vY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- ID: long (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            " |-- Label: long (nullable = true)\n",
            "\n",
            "Coefficients: [-12.262057929180484,4.087352266486688]\n",
            "Intercept: 11.56891272665312\n",
            "+---+---------+-----+----------+--------------------+\n",
            "| ID| features|Label|prediction|         probability|\n",
            "+---+---------+-----+----------+--------------------+\n",
            "|  1|[2.0,3.0]|    0|       0.0|[0.66666647815282...|\n",
            "|  2|[1.0,5.0]|    1|       1.0|[2.66352305802435...|\n",
            "|  3|[2.5,4.5]|    1|       0.0|[0.66666660367734...|\n",
            "|  4|[3.0,6.0]|    0|       0.0|[0.66666672920183...|\n",
            "+---+---------+-----+----------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b9066e04",
      "metadata": {
        "id": "b9066e04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c7b1e4c-6493-45ba-c50d-8646b6ab2218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Centers: [array([5.33333333, 5.33333333]), array([15., 15.])]\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.ml.linalg import VectorUDT\n",
        "#from pyspark.ml.feature import VectorAssembler  # No need for VectorAssembler here\n",
        "\n",
        "spark = SparkSession.builder.appName('KMeans Example').getOrCreate()\n",
        "\n",
        "# Example dataset\n",
        "data = [(1, [1.0, 1.0]), (2, [5.0, 5.0]), (3, [10.0, 10.0]), (4, [15.0, 15.0])]\n",
        "columns = ['ID', 'Features']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Convert 'Features' column to a vector column using a UDF\n",
        "\n",
        "\n",
        "array_to_vector_udf = udf(lambda x: Vectors.dense(x), VectorUDT()) # Define a UDF to convert to Vectors.dense\n",
        "df = df.withColumn('features', array_to_vector_udf('Features')) # Apply the UDF to create 'features' column\n",
        "\n",
        "# Train KMeans clustering model, using the new 'features' column\n",
        "kmeans = KMeans(featuresCol='features', k=2) # Update featuresCol to 'features'\n",
        "model = kmeans.fit(df)\n",
        "\n",
        "# Show cluster centers\n",
        "centers = model.clusterCenters()\n",
        "print(f'Cluster Centers: {centers}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a60a8d7e",
      "metadata": {
        "id": "a60a8d7e"
      },
      "source": [
        "## Homework\n",
        "- Load a real-world dataset into Spark and prepare it for machine learning tasks.\n",
        "- Build a classification model using Spark MLlib and evaluate its performance.\n",
        "- Explore hyperparameter tuning using cross-validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "4TAtTJV4KM0J",
        "outputId": "03dc6c85-31ef-416e-dada-824a4a2d6ad2"
      },
      "id": "4TAtTJV4KM0J",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-673b5b1e-c291-406c-8a26-38040c7ca86a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-673b5b1e-c291-406c-8a26-38040c7ca86a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"davidandreynugroho\",\"key\":\"ae378ea2d8627f541e29cce578d5f067\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Membuat folder .kaggle\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "\n",
        "# Memindahkan file kaggle.json ke folder .kaggle\n",
        "!mv kaggle.json /root/.kaggle/\n",
        "\n",
        "# Mengatur izin untuk file kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "9J3TI7jRKmWI"
      },
      "id": "9J3TI7jRKmWI",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"aparnashastry/building-permit-applications-data\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXpWjfTmKmdJ",
        "outputId": "2d1da519-087a-4973-e42d-ea474c9a91c4"
      },
      "id": "FXpWjfTmKmdJ",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/aparnashastry/building-permit-applications-data?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 18.0M/18.0M [00:00<00:00, 80.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/aparnashastry/building-permit-applications-data/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library yang diperlukan\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Memuat dataset CSV\n",
        "df = pd.read_csv(path + \"/Building_Permits.csv\")\n",
        "\n",
        "\n",
        "# Tampilkan informasi umum dataset\n",
        "print(\"Dataset Info:\")\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnac4sNVKmf2",
        "outputId": "ed1cd713-1a44-438b-be9b-17684d123956"
      },
      "id": "Lnac4sNVKmf2",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-7e161e0edb73>:6: DtypeWarning: Columns (22,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path + \"/Building_Permits.csv\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 198900 entries, 0 to 198899\n",
            "Data columns (total 43 columns):\n",
            " #   Column                                  Non-Null Count   Dtype  \n",
            "---  ------                                  --------------   -----  \n",
            " 0   Permit Number                           198900 non-null  object \n",
            " 1   Permit Type                             198900 non-null  int64  \n",
            " 2   Permit Type Definition                  198900 non-null  object \n",
            " 3   Permit Creation Date                    198900 non-null  object \n",
            " 4   Block                                   198900 non-null  object \n",
            " 5   Lot                                     198900 non-null  object \n",
            " 6   Street Number                           198900 non-null  int64  \n",
            " 7   Street Number Suffix                    2216 non-null    object \n",
            " 8   Street Name                             198900 non-null  object \n",
            " 9   Street Suffix                           196132 non-null  object \n",
            " 10  Unit                                    29479 non-null   float64\n",
            " 11  Unit Suffix                             1961 non-null    object \n",
            " 12  Description                             198610 non-null  object \n",
            " 13  Current Status                          198900 non-null  object \n",
            " 14  Current Status Date                     198900 non-null  object \n",
            " 15  Filed Date                              198900 non-null  object \n",
            " 16  Issued Date                             183960 non-null  object \n",
            " 17  Completed Date                          97191 non-null   object \n",
            " 18  First Construction Document Date        183954 non-null  object \n",
            " 19  Structural Notification                 6922 non-null    object \n",
            " 20  Number of Existing Stories              156116 non-null  float64\n",
            " 21  Number of Proposed Stories              156032 non-null  float64\n",
            " 22  Voluntary Soft-Story Retrofit           35 non-null      object \n",
            " 23  Fire Only Permit                        18827 non-null   object \n",
            " 24  Permit Expiration Date                  147020 non-null  object \n",
            " 25  Estimated Cost                          160834 non-null  float64\n",
            " 26  Revised Cost                            192834 non-null  float64\n",
            " 27  Existing Use                            157786 non-null  object \n",
            " 28  Existing Units                          147362 non-null  float64\n",
            " 29  Proposed Use                            156461 non-null  object \n",
            " 30  Proposed Units                          147989 non-null  float64\n",
            " 31  Plansets                                161591 non-null  float64\n",
            " 32  TIDF Compliance                         2 non-null       object \n",
            " 33  Existing Construction Type              155534 non-null  float64\n",
            " 34  Existing Construction Type Description  155534 non-null  object \n",
            " 35  Proposed Construction Type              155738 non-null  float64\n",
            " 36  Proposed Construction Type Description  155738 non-null  object \n",
            " 37  Site Permit                             5359 non-null    object \n",
            " 38  Supervisor District                     197183 non-null  float64\n",
            " 39  Neighborhoods - Analysis Boundaries     197175 non-null  object \n",
            " 40  Zipcode                                 197184 non-null  float64\n",
            " 41  Location                                197200 non-null  object \n",
            " 42  Record ID                               198900 non-null  int64  \n",
            "dtypes: float64(12), int64(3), object(28)\n",
            "memory usage: 65.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Estimated Cost'].fillna(df['Estimated Cost'].mean(), inplace=True)\n",
        "df['Number of Existing Stories'].fillna(df['Number of Existing Stories'].median(), inplace=True)\n",
        "df['Description'].fillna('No Description', inplace=True)\n",
        "\n",
        "df['Number of Proposed Stories'].fillna(df['Number of Proposed Stories'].median(), inplace=True)\n",
        "df['Revised Cost'].fillna(df['Revised Cost'].mean(), inplace=True)\n",
        "df['Existing Use'].fillna(df['Existing Use'].mode()[0], inplace=True)\n",
        "df['Existing Units'].fillna(df['Existing Units'].median(), inplace=True)\n",
        "df['Proposed Units'].fillna(df['Proposed Units'].median(), inplace=True)\n",
        "df['Plansets'].fillna(df['Plansets'].median(), inplace=True)\n",
        "df['Existing Construction Type'].fillna(df['Existing Construction Type'].mode()[0], inplace=True)\n",
        "df['Proposed Construction Type'].fillna(df['Proposed Construction Type'].mode()[0], inplace=True)\n",
        "df['Supervisor District'].fillna(df['Supervisor District'].median(), inplace=True)\n",
        "\n",
        "df['Permit Expiration Date'].fillna(df['Permit Expiration Date'].mode()[0], inplace=True)\n",
        "df['Issued Date'].fillna(df['Issued Date'].mode()[0], inplace=True) #\n",
        "df['First Construction Document Date'].fillna(df['First Construction Document Date'].mode()[0], inplace=True)\n",
        "df['Existing Construction Type Description'].fillna(df['Existing Construction Type Description'].mode()[0], inplace=True)\n",
        "df['Proposed Construction Type Description'].fillna(df['Proposed Construction Type Description'].mode()[0], inplace=True)\n",
        "\n",
        "\n",
        "df.dropna(subset=['Street Suffix'], inplace=True)\n",
        "df.dropna(subset=['Neighborhoods - Analysis Boundaries'], inplace=True)\n",
        "df.dropna(subset=['Proposed Use'], inplace=True)\n",
        "df.dropna(subset=['Zipcode'], inplace=True)\n",
        "\n",
        "df.drop(columns=['Street Number Suffix', 'Unit', 'Completed Date', 'Voluntary Soft-Story Retrofit', 'TIDF Compliance', 'Unit Suffix',\n",
        "                'Structural Notification', 'Site Permit', 'Fire Only Permit'\n",
        "                ], inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0Uy1qdwKmjy",
        "outputId": "55fc6255-3680-4163-96a2-dba3195b6852"
      },
      "id": "w0Uy1qdwKmjy",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-3d4e8e825b90>:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Estimated Cost'].fillna(df['Estimated Cost'].mean(), inplace=True)\n",
            "<ipython-input-7-3d4e8e825b90>:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Number of Existing Stories'].fillna(df['Number of Existing Stories'].median(), inplace=True)\n",
            "<ipython-input-7-3d4e8e825b90>:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Description'].fillna('No Description', inplace=True)\n",
            "<ipython-input-7-3d4e8e825b90>:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Number of Proposed Stories'].fillna(df['Number of Proposed Stories'].median(), inplace=True)\n",
            "<ipython-input-7-3d4e8e825b90>:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Revised Cost'].fillna(df['Revised Cost'].mean(), inplace=True)\n",
            "<ipython-input-7-3d4e8e825b90>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Existing Units'].fillna(df['Existing Units'].median(), inplace=True)\n",
            "<ipython-input-7-3d4e8e825b90>:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Proposed Units'].fillna(df['Proposed Units'].median(), inplace=True)\n",
            "<ipython-input-7-3d4e8e825b90>:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Plansets'].fillna(df['Plansets'].median(), inplace=True)\n",
            "<ipython-input-7-3d4e8e825b90>:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Existing Construction Type'].fillna(df['Existing Construction Type'].mode()[0], inplace=True)\n",
            "<ipython-input-7-3d4e8e825b90>:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Proposed Construction Type'].fillna(df['Proposed Construction Type'].mode()[0], inplace=True)\n",
            "<ipython-input-7-3d4e8e825b90>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Supervisor District'].fillna(df['Supervisor District'].median(), inplace=True)\n",
            "<ipython-input-7-3d4e8e825b90>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Permit Expiration Date'].fillna(df['Permit Expiration Date'].mode()[0], inplace=True)\n",
            "<ipython-input-7-3d4e8e825b90>:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Issued Date'].fillna(df['Issued Date'].mode()[0], inplace=True) #\n",
            "<ipython-input-7-3d4e8e825b90>:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['First Construction Document Date'].fillna(df['First Construction Document Date'].mode()[0], inplace=True)\n",
            "<ipython-input-7-3d4e8e825b90>:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Existing Construction Type Description'].fillna(df['Existing Construction Type Description'].mode()[0], inplace=True)\n",
            "<ipython-input-7-3d4e8e825b90>:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Proposed Construction Type Description'].fillna(df['Proposed Construction Type Description'].mode()[0], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Permit Number'] = pd.to_numeric(df['Permit Number'], errors='coerce')\n",
        "# Convert date columns\n",
        "date_columns = ['Permit Creation Date', 'Current Status Date', 'Filed Date', 'Issued Date', 'First Construction Document Date']\n",
        "for col in date_columns:\n",
        "    df[col] = pd.to_datetime(df[col], errors='coerce')"
      ],
      "metadata": {
        "id": "t4CflRV0Kmml"
      },
      "id": "t4CflRV0Kmml",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXoQkWnqK7zd",
        "outputId": "acb49258-456a-4346-bedc-e8ebd2918e5f"
      },
      "id": "qXoQkWnqK7zd",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 153202 entries, 2 to 198885\n",
            "Data columns (total 34 columns):\n",
            " #   Column                                  Non-Null Count   Dtype         \n",
            "---  ------                                  --------------   -----         \n",
            " 0   Permit Number                           153202 non-null  int64         \n",
            " 1   Permit Type                             153202 non-null  int64         \n",
            " 2   Permit Type Definition                  153202 non-null  object        \n",
            " 3   Permit Creation Date                    153202 non-null  datetime64[ns]\n",
            " 4   Block                                   153202 non-null  object        \n",
            " 5   Lot                                     153202 non-null  object        \n",
            " 6   Street Number                           153202 non-null  int64         \n",
            " 7   Street Name                             153202 non-null  object        \n",
            " 8   Street Suffix                           153202 non-null  object        \n",
            " 9   Description                             153202 non-null  object        \n",
            " 10  Current Status                          153202 non-null  object        \n",
            " 11  Current Status Date                     153202 non-null  datetime64[ns]\n",
            " 12  Filed Date                              153202 non-null  datetime64[ns]\n",
            " 13  Issued Date                             153202 non-null  datetime64[ns]\n",
            " 14  First Construction Document Date        153202 non-null  datetime64[ns]\n",
            " 15  Number of Existing Stories              153202 non-null  float64       \n",
            " 16  Number of Proposed Stories              153202 non-null  float64       \n",
            " 17  Permit Expiration Date                  153202 non-null  object        \n",
            " 18  Estimated Cost                          153202 non-null  float64       \n",
            " 19  Revised Cost                            153202 non-null  float64       \n",
            " 20  Existing Use                            153202 non-null  object        \n",
            " 21  Existing Units                          153202 non-null  float64       \n",
            " 22  Proposed Use                            153202 non-null  object        \n",
            " 23  Proposed Units                          153202 non-null  float64       \n",
            " 24  Plansets                                153202 non-null  float64       \n",
            " 25  Existing Construction Type              153202 non-null  float64       \n",
            " 26  Existing Construction Type Description  153202 non-null  object        \n",
            " 27  Proposed Construction Type              153202 non-null  float64       \n",
            " 28  Proposed Construction Type Description  153202 non-null  object        \n",
            " 29  Supervisor District                     153202 non-null  float64       \n",
            " 30  Neighborhoods - Analysis Boundaries     153202 non-null  object        \n",
            " 31  Zipcode                                 153202 non-null  float64       \n",
            " 32  Location                                153202 non-null  object        \n",
            " 33  Record ID                               153202 non-null  int64         \n",
            "dtypes: datetime64[ns](5), float64(11), int64(4), object(14)\n",
            "memory usage: 40.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize a Spark session\n",
        "spark = SparkSession.builder.appName(\"BuildingPermitML\").getOrCreate()\n",
        "\n",
        "# Load the dataset into a Spark DataFrame\n",
        "spark_df = spark.createDataFrame(df)\n",
        "\n",
        "# Display the schema of the Spark DataFrame\n",
        "spark_df.printSchema()\n",
        "\n",
        "# Display the first few rows of the Spark DataFrame\n",
        "spark_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1do5xyfLCTj",
        "outputId": "b3e5828c-a405-48bb-a409-4546c79bc8a5"
      },
      "id": "s1do5xyfLCTj",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Permit Number: long (nullable = true)\n",
            " |-- Permit Type: long (nullable = true)\n",
            " |-- Permit Type Definition: string (nullable = true)\n",
            " |-- Permit Creation Date: timestamp (nullable = true)\n",
            " |-- Block: string (nullable = true)\n",
            " |-- Lot: string (nullable = true)\n",
            " |-- Street Number: long (nullable = true)\n",
            " |-- Street Name: string (nullable = true)\n",
            " |-- Street Suffix: string (nullable = true)\n",
            " |-- Description: string (nullable = true)\n",
            " |-- Current Status: string (nullable = true)\n",
            " |-- Current Status Date: timestamp (nullable = true)\n",
            " |-- Filed Date: timestamp (nullable = true)\n",
            " |-- Issued Date: timestamp (nullable = true)\n",
            " |-- First Construction Document Date: timestamp (nullable = true)\n",
            " |-- Number of Existing Stories: double (nullable = true)\n",
            " |-- Number of Proposed Stories: double (nullable = true)\n",
            " |-- Permit Expiration Date: string (nullable = true)\n",
            " |-- Estimated Cost: double (nullable = true)\n",
            " |-- Revised Cost: double (nullable = true)\n",
            " |-- Existing Use: string (nullable = true)\n",
            " |-- Existing Units: double (nullable = true)\n",
            " |-- Proposed Use: string (nullable = true)\n",
            " |-- Proposed Units: double (nullable = true)\n",
            " |-- Plansets: double (nullable = true)\n",
            " |-- Existing Construction Type: double (nullable = true)\n",
            " |-- Existing Construction Type Description: string (nullable = true)\n",
            " |-- Proposed Construction Type: double (nullable = true)\n",
            " |-- Proposed Construction Type Description: string (nullable = true)\n",
            " |-- Supervisor District: double (nullable = true)\n",
            " |-- Neighborhoods - Analysis Boundaries: string (nullable = true)\n",
            " |-- Zipcode: double (nullable = true)\n",
            " |-- Location: string (nullable = true)\n",
            " |-- Record ID: long (nullable = true)\n",
            "\n",
            "+-------------+-----------+----------------------+--------------------+-----+----+-------------+-----------+-------------+--------------------+--------------+-------------------+-------------------+-------------------+--------------------------------+--------------------------+--------------------------+----------------------+--------------+-----------------+-----------------+--------------+-----------------+--------------+--------+--------------------------+--------------------------------------+--------------------------+--------------------------------------+-------------------+-----------------------------------+-------+--------------------+-------------+\n",
            "|Permit Number|Permit Type|Permit Type Definition|Permit Creation Date|Block| Lot|Street Number|Street Name|Street Suffix|         Description|Current Status|Current Status Date|         Filed Date|        Issued Date|First Construction Document Date|Number of Existing Stories|Number of Proposed Stories|Permit Expiration Date|Estimated Cost|     Revised Cost|     Existing Use|Existing Units|     Proposed Use|Proposed Units|Plansets|Existing Construction Type|Existing Construction Type Description|Proposed Construction Type|Proposed Construction Type Description|Supervisor District|Neighborhoods - Analysis Boundaries|Zipcode|            Location|    Record ID|\n",
            "+-------------+-----------+----------------------+--------------------+-----+----+-------------+-----------+-------------+--------------------+--------------+-------------------+-------------------+-------------------+--------------------------------+--------------------------+--------------------------+----------------------+--------------+-----------------+-----------------+--------------+-----------------+--------------+--------+--------------------------+--------------------------------------+--------------------------+--------------------------------------+-------------------+-----------------------------------+-------+--------------------+-------------+\n",
            "| 201605278609|          3|  additions alterat...| 2016-05-27 00:00:00| 0595| 203|         1647|    Pacific|           Av|installation of s...|     withdrawn|2017-09-26 00:00:00|2016-05-27 00:00:00|2016-06-15 00:00:00|             2016-11-07 00:00:00|                       6.0|                       6.0|            02/28/2018|       20000.0|132856.1864917494|     retail sales|          39.0|     retail sales|          39.0|     2.0|                       1.0|                         constr type 1|                       1.0|                         constr type 1|                3.0|                       Russian Hill|94109.0|(37.7946573324287...|1424856504716|\n",
            "| 201611072166|          8|  otc alterations p...| 2016-11-07 00:00:00| 0156| 011|         1230|    Pacific|           Av|repair dryrot & s...|      complete|2017-07-24 00:00:00|2016-11-07 00:00:00|2017-07-18 00:00:00|             2017-07-18 00:00:00|                       2.0|                       2.0|            07/13/2018|        2000.0|           2000.0|1 family dwelling|           1.0|1 family dwelling|           1.0|     2.0|                       5.0|                        wood frame (5)|                       5.0|                        wood frame (5)|                3.0|                           Nob Hill|94109.0|(37.7959586790916...|1443574295566|\n",
            "| 201706149344|          8|  otc alterations p...| 2017-06-14 00:00:00| 4105| 009|          800|    Indiana|           St|           evac maps|        issued|2017-07-06 00:00:00|2017-06-14 00:00:00|2017-07-06 00:00:00|             2017-07-06 00:00:00|                       5.0|                       5.0|            07/01/2018|        4000.0|           4000.0|       apartments|         326.0|       apartments|         326.0|     2.0|                       1.0|                         constr type 1|                       1.0|                         constr type 1|               10.0|                       Potrero Hill|94107.0|(37.7592233134653...|1466911170855|\n",
            "| 201706300814|          8|  otc alterations p...| 2017-06-30 00:00:00| 1739| 020|         1291|       11th|           Av|          re-roofing|      complete|2017-07-12 00:00:00|2017-06-30 00:00:00|2017-06-30 00:00:00|             2017-06-30 00:00:00|                       3.0|                       3.0|            06/25/2018|       12000.0|          12000.0|       apartments|           5.0|       apartments|           5.0|     0.0|                       5.0|                        wood frame (5)|                       5.0|                        wood frame (5)|                5.0|                       Inner Sunset|94122.0|(37.7641456401385...|1468970403692|\n",
            "| 201707252846|          8|  otc alterations p...| 2017-07-25 00:00:00| 6589|002R|          681|       27th|           St|remove and replac...|         filed|2017-07-25 00:00:00|2017-07-25 00:00:00|2016-06-15 00:00:00|             2016-11-07 00:00:00|                       2.0|                       2.0|            02/28/2018|       30000.0|              0.0|1 family dwelling|           1.0|1 family dwelling|           1.0|     2.0|                       5.0|                        wood frame (5)|                       5.0|                        wood frame (5)|                8.0|                         Noe Valley|94131.0|(37.7462205625642...|1471799208305|\n",
            "+-------------+-----------+----------------------+--------------------+-----+----+-------------+-----------+-------------+--------------------+--------------+-------------------+-------------------+-------------------+--------------------------------+--------------------------+--------------------------+----------------------+--------------+-----------------+-----------------+--------------+-----------------+--------------+--------+--------------------------+--------------------------------------+--------------------------+--------------------------------------+-------------------+-----------------------------------+-------+--------------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a classification model using Spark MLlib and evaluate its performance."
      ],
      "metadata": {
        "id": "ov-6RBYMLYeo"
      },
      "id": "ov-6RBYMLYeo"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "\n",
        "# Convert 'Permit Type' to a numeric label using StringIndexer\n",
        "indexer = StringIndexer(inputCol=\"Permit Type\", outputCol=\"label\")\n",
        "\n",
        "# Use VectorAssembler to combine features into a single feature vector\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"Number of Existing Stories\", \"Number of Proposed Stories\", \"Estimated Cost\", \"Revised Cost\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "# Initialize Random Forest Classifier\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
        "\n",
        "# Create a pipeline to chain the steps\n",
        "pipeline = Pipeline(stages=[indexer, assembler, rf])\n",
        "\n",
        "# Split data into training and testing sets (80% train, 20% test)\n",
        "train_data, test_data = spark_df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model = pipeline.fit(train_data)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Evaluate the model's accuracy using MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy}\")\n",
        "print(f\"Training Data Count: {train_data.count()}\")\n",
        "print(f\"Test Data Count: {test_data.count()}\")\n",
        "\n",
        "rf_model = model.stages[2]  # Model RandomForestClassifier\n",
        "\n",
        "# Menampilkan feature importances\n",
        "print(\"Feature Importances: \", rf_model.featureImportances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOQOG84YK72S",
        "outputId": "4a1fd610-8a10-4f35-eb96-247859c4c595"
      },
      "id": "GOQOG84YK72S",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.9325390384053501\n",
            "Training Data Count: 122399\n",
            "Test Data Count: 30803\n",
            "Feature Importances:  (4,[0,1,2,3],[0.08186776485813532,0.03333337484289456,0.14307868666644025,0.7417201736325298])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore hyperparameter tuning using cross-validation."
      ],
      "metadata": {
        "id": "f0bdyLy1Lc5b"
      },
      "id": "f0bdyLy1Lc5b"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Definisikan parameter grid untuk tuning\n",
        "paramGrid = (ParamGridBuilder()\n",
        "             .addGrid(rf.numTrees, [10, 20, 30])  # Jumlah pohon\n",
        "             .addGrid(rf.maxDepth, [5, 10, 15])   # Kedalaman maksimum pohon\n",
        "             .build())\n",
        "\n",
        "# Evaluator untuk cross-validation\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "# Inisialisasi CrossValidator\n",
        "crossval = CrossValidator(estimator=pipeline,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=evaluator,\n",
        "                          numFolds=5)  # 5-fold cross-validation\n",
        "\n",
        "# Lakukan cross-validation pada data pelatihan\n",
        "cvModel = crossval.fit(train_data)\n",
        "\n",
        "# Lakukan prediksi pada data pengujian\n",
        "cvPredictions = cvModel.transform(test_data)\n",
        "\n",
        "# Evaluasi model yang di-tuning\n",
        "cvAccuracy = evaluator.evaluate(cvPredictions)\n",
        "\n",
        "# Tampilkan hasil akurasi setelah tuning hiperparameter\n",
        "print(f\"Accuracy after Hyperparameter Tuning: {cvAccuracy}\")\n",
        "\n",
        "rf_model2 = cvModel.bestModel.stages[2]  # Model RandomForestClassifier\n",
        "\n",
        "# Menampilkan fitur penting (feature importances)\n",
        "print(\"Feature Importances: \", rf_model2.featureImportances)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iU6UW1dK74_",
        "outputId": "9b6428df-9099-465d-81ad-8c424340d8a7"
      },
      "id": "_iU6UW1dK74_",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after Hyperparameter Tuning: 0.9371814433659059\n",
            "Feature Importances:  (4,[0,1,2,3],[0.10871532346011045,0.06606199384473115,0.1478452053872751,0.6773774773078834])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "22YPOSRIK8CW"
      },
      "id": "22YPOSRIK8CW",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}